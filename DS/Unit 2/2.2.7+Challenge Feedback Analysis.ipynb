{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>he was extremely rude and really there are so ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>they know how to make them here</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>dont bother coming here</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not tasty and the texture was just nasty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>we ordered the duck rare and it was pink and t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "138  he was extremely rude and really there are so ...          0\n",
       "258                    they know how to make them here          1\n",
       "937                            dont bother coming here          0\n",
       "2             not tasty and the texture was just nasty          0\n",
       "50   we ordered the duck rare and it was pink and t...          1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import all review datasets: yelp, imdb and amazon\n",
    "import pandas as pd\n",
    "import re\n",
    "# Grab and process the raw data.\n",
    "data_path = (\"../../../Data & Script/sentiment labelled sentences/yelp_labelled.txt\")\n",
    "yelp = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "data_path = (\"../../../Data & Script/sentiment labelled sentences/imdb_labelled.txt\")\n",
    "imdb = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "data_path = (\"../../../Data & Script/sentiment labelled sentences/amazon_cells_labelled.txt\")\n",
    "amazon = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "amazon.columns = ['review', 'sentiment']\n",
    "yelp.columns = ['review', 'sentiment']\n",
    "# convert to lower case\n",
    "yelp['review'] = yelp['review'].str.lower()\n",
    "amazon['review'] = amazon['review'].str.lower()\n",
    "\n",
    "# remove punctuation\n",
    "yelp['review'] = yelp['review'].str.replace('[^\\w\\s]','')\n",
    "amazon['review'] = amazon['review'].str.replace('[^\\w\\s]','')\n",
    "                  \n",
    "# remove numbers\n",
    "yelp['review'] = yelp['review'].str.replace('\\d','')\n",
    "amazon['review'] = amazon['review'].str.replace('\\d','')\n",
    "                  \n",
    "\n",
    "yelp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of  1130  positve words\n",
      "A total of  1265  negative words\n"
     ]
    }
   ],
   "source": [
    "# create a word count vector for positive and negative reviews separetly\n",
    "from collections import Counter\n",
    "# combine all strings in positive reviews and remove punctuation\n",
    "positive_reviews = \" \".join(yelp[yelp['sentiment'] == 1]['review']).lower()\n",
    "# combine all strings in spam email and remove punctuation\n",
    "negative_reviews = \" \".join(yelp[yelp['sentiment'] == 0]['review']).lower()\n",
    "\n",
    "positive_word_count = Counter(positive_reviews.split(\" \"))\n",
    "negative_word_count = Counter(negative_reviews.split(\" \"))\n",
    "\n",
    "# Ignore stop words and find most common words\n",
    "from nltk.corpus import stopwords\n",
    "# all english stop words\n",
    "en_stops = set(stopwords.words('english'))\n",
    "# take only non-stop words\n",
    "top_positive_words = [w for w, c in positive_word_count.most_common() if w not in en_stops]\n",
    "top_negative_words = [w for w, c in negative_word_count.most_common() if w not in en_stops]\n",
    "\n",
    "print(\"A total of \", len(top_positive_words), \" positve words\")\n",
    "print(\"A total of \", len(top_negative_words), \" negative words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'great',\n",
       " 'food',\n",
       " 'place',\n",
       " '',\n",
       " 'service',\n",
       " 'friendly',\n",
       " 'delicious',\n",
       " 'back',\n",
       " 'nice',\n",
       " 'time',\n",
       " 'really',\n",
       " 'best',\n",
       " 'amazing',\n",
       " 'also',\n",
       " 'like',\n",
       " 'restaurant',\n",
       " 'go',\n",
       " 'love',\n",
       " 'staff',\n",
       " 'vegas',\n",
       " 'first',\n",
       " 'menu',\n",
       " 'always',\n",
       " 'fantastic',\n",
       " 'experience',\n",
       " 'awesome',\n",
       " 'pretty',\n",
       " 'made',\n",
       " 'loved',\n",
       " 'definitely',\n",
       " 'fresh',\n",
       " 'one',\n",
       " 'steak',\n",
       " 'excellent',\n",
       " 'even',\n",
       " 'atmosphere',\n",
       " 'pizza',\n",
       " 'perfect',\n",
       " 'prices',\n",
       " 'server',\n",
       " 'ever',\n",
       " 'im',\n",
       " 'chicken',\n",
       " 'selection',\n",
       " 'could',\n",
       " 'tasty',\n",
       " 'came',\n",
       " 'stars',\n",
       " 'well']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find top 50 positives\n",
    "top_positive_words[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'food',\n",
       " 'place',\n",
       " 'back',\n",
       " 'service',\n",
       " 'like',\n",
       " 'go',\n",
       " 'dont',\n",
       " 'good',\n",
       " 'never',\n",
       " 'would',\n",
       " 'time',\n",
       " 'ever',\n",
       " 'minutes',\n",
       " 'bad',\n",
       " 'one',\n",
       " 'much',\n",
       " 'got',\n",
       " 'wont',\n",
       " 'really',\n",
       " 'disappointed',\n",
       " 'worst',\n",
       " 'think',\n",
       " 'going',\n",
       " 'wasnt',\n",
       " 'ive',\n",
       " 'came',\n",
       " 'eat',\n",
       " 'us',\n",
       " 'im',\n",
       " 'slow',\n",
       " 'get',\n",
       " 'wait',\n",
       " 'bland',\n",
       " 'better',\n",
       " 'well',\n",
       " 'way',\n",
       " 'waited',\n",
       " 'flavor',\n",
       " 'probably',\n",
       " 'terrible',\n",
       " 'didnt',\n",
       " 'times',\n",
       " 'ordered',\n",
       " 'also',\n",
       " 'another',\n",
       " 'even',\n",
       " 'could',\n",
       " 'say',\n",
       " 'overpriced']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find top 50 negative words\n",
    "top_negative_words[:50]\n",
    "#selected_negative_words = ['go','dont','ever','never','bad','better','not','falvor','even','say']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_data(data, keywords):\n",
    "    # Next create the features\n",
    "    # take all positive and negative words as features\n",
    "    # copy by value(deep copy)\n",
    "    data_mod = data.copy(deep=True)\n",
    "\n",
    "    if \"review\" in keywords:\n",
    "        keywords.remove(\"review\")  \n",
    "    if \"\" in keywords:\n",
    "        keywords.remove(\"\")\n",
    "        \n",
    "    for key in keywords:\n",
    "        data_mod[key] = data_mod.review.str.contains(' ' + key + ' ', case=False) \n",
    "    \n",
    "    return data_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose positive words which didn't occur in the top 1000/100 negative words\n",
    "positive_words_big = [w for w in top_positive_words[:1000] if w not in top_negative_words[:1000]]\n",
    "positive_words_small = [w for w in top_positive_words[:100] if w not in top_negative_words[:100]]\n",
    "\n",
    "# choose negative words which didn't occur in the top 1000/100 positive words\n",
    "negative_words_big = [w for w in top_negative_words[:1000] if w not in top_positive_words[:1000]]\n",
    "negative_words_small = [w for w in top_negative_words[:100] if w not in top_positive_words[:100]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 281, accuracy: 71.90% \n"
     ]
    }
   ],
   "source": [
    "# trying small set of features\n",
    "keywords_small = positive_words_small + negative_words_small\n",
    "yelp_small = create_binary_data(yelp, keywords_small)\n",
    "# Now train model and calculate accuracy on training set\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model_small = BernoulliNB()\n",
    "data = yelp_small[keywords_small]\n",
    "target = yelp_small['sentiment']\n",
    "model_small.fit(data, target)\n",
    "y_pred = model_small.predict(data)\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, accuracy: {:.2f}% \".format(data.shape[0],(target != y_pred).sum(), ((target == y_pred).sum()/data.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 163, accuracy: 83.70% \n"
     ]
    }
   ],
   "source": [
    "# trying big set of features\n",
    "keywords_big = positive_words_big + negative_words_big\n",
    "yelp_big = create_binary_data(yelp, keywords_big)\n",
    "# Now train model and calculate accuracy on training set\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model_big = BernoulliNB()\n",
    "data = yelp_big[keywords_big]\n",
    "target = yelp_big['sentiment']\n",
    "model_big.fit(data, target)\n",
    "y_pred = model_big.predict(data)\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, accuracy: {:.2f}% \".format(data.shape[0],(target != y_pred).sum(), ((target == y_pred).sum()/data.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 156, accuracy: 84.40% \n"
     ]
    }
   ],
   "source": [
    "# add some more features from misclassfied reviews\n",
    "false_positives = yelp[(target != y_pred) & (target == 0)]\n",
    "false_negatives = yelp[(target != y_pred) & (target == 1)]\n",
    "\n",
    "false_positive_words = []\n",
    "false_negative_words = []\n",
    "false_positives = \" \".join(false_positives['review']).lower()\n",
    "false_negatives = \" \".join(false_negatives['review']).lower()\n",
    "\n",
    "fp_count = Counter(false_negatives.split(\" \"))\n",
    "fn_count = Counter(false_negatives.split(\" \"))\n",
    "\n",
    "\n",
    "top_fp_count = [w for w, c in fp_count.most_common() if w not in en_stops]\n",
    "top_fn_count = [w for w, c in fn_count.most_common() if w not in en_stops]\n",
    "\n",
    "# Add new words to existing big set of keywords and retrain model\n",
    "# combine new features with existing ones and find distinct features.\n",
    "keywords_combin = set(top_fp_count + top_fn_count + keywords_big)\n",
    "\n",
    "yelp_combin = create_binary_data(yelp, keywords_combin)\n",
    "\n",
    "model_combin = BernoulliNB()\n",
    "data = yelp_combin[list(keywords_combin)]\n",
    "target = yelp_combin['sentiment']\n",
    "model_combin.fit(data, target)\n",
    "y_pred = model_combin.predict(data)\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, accuracy: {:.2f}% \".format(data.shape[0],(target != y_pred).sum(), ((target == y_pred).sum()/data.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76, 0.76, 0.64, 0.73, 0.72, 0.75, 0.74, 0.73, 0.66, 0.67])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model_combin, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 431, accuracy: 56.90% \n"
     ]
    }
   ],
   "source": [
    "# try to use the model_combin for predicting amazon reviews, I achieved 84.40 % accuracy, now let me try to use it for amazon reviews\n",
    "# create the features for amazon\n",
    "amazon_combin = create_binary_data(amazon, keywords_combin)\n",
    "data = amazon_combin[list(keywords_combin)]\n",
    "target = amazon['sentiment']\n",
    "y_pred = model_combin.predict(data)\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, accuracy: {:.2f}% \".format(data.shape[0],(target != y_pred).sum(), ((target == y_pred).sum()/data.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excellent value</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great for the jawbone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mic is great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  so there is no way for me to plug it in here i...          0\n",
       "1                          good case excellent value          1\n",
       "2                              great for the jawbone          1\n",
       "3  tied to charger for conversations lasting more...          0\n",
       "4                                   the mic is great          1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 442, accuracy: 55.80% \n"
     ]
    }
   ],
   "source": [
    "# I think my model is overfitting to yelp and it has a lot of features, let me try it with small set of features\n",
    "# try to use the model for predicting amazon reviews, I achieved 84.40 % accuracy, now let me try to use it for amazon reviews\n",
    "# create the features for amazon\n",
    "amazon_small = create_binary_data(amazon, keywords_small)\n",
    "data = amazon_small[list(keywords_small)]\n",
    "target = amazon_small['sentiment']\n",
    "y_pred = model_small.predict(data)\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, accuracy: {:.2f}% \".format(data.shape[0],(target != y_pred).sum(), ((target == y_pred).sum()/data.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 431, accuracy: 56.90% \n"
     ]
    }
   ],
   "source": [
    "# now let me try it with big set of features excluding words from misclassfied yelp reviews\n",
    "# I think my model is overfitting to yelp and it has a lot of features, let me try it with small set of features\n",
    "# try to use the model for predicting amazon reviews, I achieved 84.40 % accuracy, now let me try to use it for amazon reviews\n",
    "# create the features for amazon\n",
    "amazon_big = create_binary_data(amazon, keywords_big)\n",
    "data = amazon_big[list(keywords_big)]\n",
    "target = amazon_big['sentiment']\n",
    "y_pred = model_big.predict(data)\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, accuracy: {:.2f}% \".format(data.shape[0],(target != y_pred).sum(), ((target == y_pred).sum()/data.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** A model with small set of features resulted low accuracy(71.90%) on training data. Using much larger feature set improved the accuracy to 83.70% and further adding some more words that occured in the misclassfied reviews increased the accuracy to 84.00%. The model is not as accurate when tested on amazon reviews, it is only 55.80 or 56.90% accurate. A better solution might be to train a model using reviews from all companies(yelp, amazon and imdb) and create a model that has small training error as well as generalize well across all companies reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
